{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "env: WANDB_DISABLED=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencerdearman/sentiment-analysis/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "# Ensure environment settings for tokenizers and wandb\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env WANDB_DISABLED=true\n",
    "\n",
    "# Install required packages\n",
    "# %pip install numpy pandas scikit-learn transformers datasets evaluate torch tqdm\n",
    "\n",
    "# Now import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Verify if torch was installed successfully\n",
    "try:\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch installation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "  model = 'ProsusAI/finbert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all-data.csv', names=['labels', 'messages'], encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages    labels\n",
       "0  According to Gran , the company has no plans t...   neutral\n",
       "1  Technopolis plans to develop in stages an area...   neutral\n",
       "2  The international electronic industry company ...  negative\n",
       "3  With the new production plant the company woul...  positive\n",
       "4  According to the company 's updated strategy f...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['messages', 'labels']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "1    2879\n",
       "2    1363\n",
       "0     604\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['labels'])\n",
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['messages'].values, df['labels'].values\n",
    "\n",
    "# train : test = 0.9 : 0.1\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "\n",
    "# train : valid = 0.8 : 0.2\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(xtrain, ytrain, test_size=0.2, stratify=ytrain)\n",
    "\n",
    "# train : valid : test = 0.72 : 0.18 : 0.10 (stratified on 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_raw = Dataset.from_dict({'text':xtrain, 'labels':ytrain})\n",
    "valid_dataset_raw = Dataset.from_dict({'text':xvalid, 'labels':yvalid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 3488\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3488/3488 [00:00<00:00, 17647.98 examples/s]\n",
      "Map: 100%|██████████| 873/873 [00:00<00:00, 18644.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset_raw.map(tokenize_fn, batched=True)\n",
    "valid_dataset = valid_dataset_raw.map(tokenize_fn, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {'accuracy': accuracy_score(labels, preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencerdearman/sentiment-analysis/.venv/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    './Finbert Trained/',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=2*16,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,    \n",
    "    do_eval=True,\n",
    "    do_train=True,\n",
    "    do_predict=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy=\"no\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/1dtb5n794qbf5bn8fxwmn2zw0000gn/T/ipykernel_66455/2761071322.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 219/1090 [00:45<16:24,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39340025186538696, 'eval_accuracy': 0.843069873997709, 'eval_runtime': 3.2965, 'eval_samples_per_second': 264.825, 'eval_steps_per_second': 8.494, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 40%|████      | 437/1090 [01:21<08:26,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30324220657348633, 'eval_accuracy': 0.8854524627720504, 'eval_runtime': 2.0961, 'eval_samples_per_second': 416.488, 'eval_steps_per_second': 13.358, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 501/1090 [01:31<01:34,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5708, 'grad_norm': 1.5953829288482666, 'learning_rate': 1.2028542303771661e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 60%|██████    | 655/1090 [01:57<05:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42314985394477844, 'eval_accuracy': 0.8694158075601375, 'eval_runtime': 2.136, 'eval_samples_per_second': 408.71, 'eval_steps_per_second': 13.109, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 80%|████████  | 873/1090 [02:32<02:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4458830952644348, 'eval_accuracy': 0.8843069873997709, 'eval_runtime': 2.1248, 'eval_samples_per_second': 410.868, 'eval_steps_per_second': 13.178, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1001/1090 [02:51<00:13,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0779, 'grad_norm': 0.14419539272785187, 'learning_rate': 1.8348623853211011e-06, 'epoch': 4.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 1090/1090 [03:07<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44380295276641846, 'eval_accuracy': 0.8900343642611683, 'eval_runtime': 2.1185, 'eval_samples_per_second': 412.088, 'eval_steps_per_second': 13.217, 'epoch': 5.0}\n",
      "{'train_runtime': 187.2477, 'train_samples_per_second': 93.139, 'train_steps_per_second': 5.821, 'train_loss': 0.3001344844835614, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1090, training_loss=0.3001344844835614, metrics={'train_runtime': 187.2477, 'train_samples_per_second': 93.139, 'train_steps_per_second': 5.821, 'total_flos': 533404898383392.0, 'train_loss': 0.3001344844835614, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('finbert_finetuned.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 485\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dataset_raw = Dataset.from_dict({'text': xtest})\n",
    "pred_dataset_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 485/485 [00:00<00:00, 11236.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "pred_dataset = pred_dataset_raw.map(tokenize_fn, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  9.86it/s]\n"
     ]
    }
   ],
   "source": [
    "output = trainer.predict(\n",
    "    test_dataset=pred_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'negative', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'negative', 'positive', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'negative', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'negative', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'positive', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'neutral', 'positive', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'negative', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'negative', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'positive', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'negative', 'positive', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'negative', 'positive',\n",
       "       'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([np.argmax(x) for x in output.predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [np.argmax(x) for x in output.predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989690721649485"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
